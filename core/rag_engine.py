from typing import List, Dict, Any
from datetime import datetime

class RAGEngine:
    """RAGæ ¸å¿ƒå¼•æ“Ž"""
    
    def __init__(self, notion_client, text_processor, embedder, vector_store, settings):
        self.notion_client = notion_client
        self.text_processor = text_processor
        self.embedder = embedder
        self.vector_store = vector_store
        self.settings = settings
        
        # è¨­å®šOpenAI
        if settings.USE_OPENAI and settings.OPENAI_API_KEY:
            try:
                from openai import OpenAI
                self.openai_client = OpenAI(api_key=settings.OPENAI_API_KEY)
                self.use_openai = True
                print(f"âœ… OpenAI API å·²è¨­å®šï¼Œæ¨¡åž‹: {settings.OPENAI_MODEL}")
            except ImportError:
                print("âŒ OpenAI å¥—ä»¶æœªå®‰è£ï¼Œä½¿ç”¨ç°¡å–®å›žæ‡‰")
                self.use_openai = False
            except Exception as e:
                print(f"âŒ OpenAI è¨­å®šå¤±æ•—: {e}")
                self.use_openai = False
        else:
            self.use_openai = False
            print("âš ï¸ æœªè¨­å®šOpenAI APIï¼Œå°‡ä½¿ç”¨ç°¡å–®çš„æ–‡æœ¬çµ„åˆå›žæ‡‰")
    
    def process_notion_page(self, page_id: str) -> bool:
        """è™•ç†Notioné é¢ä¸¦åŠ å…¥å‘é‡è³‡æ–™åº«"""
        try:
            print(f"ðŸ“„ é–‹å§‹è™•ç†Notioné é¢: {page_id}")
            
            # ç²å–é é¢å…§å®¹
            print("ðŸ”„ ç²å–é é¢å…§å®¹...")
            raw_text = self.notion_client.get_page_content(page_id)
            
            # æ¸…ç†å’Œåˆ†å‰²æ–‡æœ¬
            print("ðŸ§¹ æ¸…ç†å’Œåˆ†å‰²æ–‡æœ¬...")
            cleaned_text = self.text_processor.clean_text(raw_text)
            chunks = self.text_processor.split_text(cleaned_text)
            
            print(f"âœ‚ï¸ æ–‡æœ¬åˆ†å‰²å®Œæˆï¼Œå…± {len(chunks)} å€‹ç‰‡æ®µ")
            
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒä¾†æºçš„è³‡æ–™
            source_name = f"notion_page_{page_id}"
            existing_stats = self.vector_store.get_stats()
            
            if source_name in existing_stats.get('source_stats', {}):
                print(f"âš ï¸ ç™¼ç¾ç¾æœ‰è³‡æ–™ï¼Œå°‡æ¸…ç©ºå¾Œé‡æ–°è™•ç†")
                self.vector_store.clear_database()
            
            # ç”Ÿæˆå‘é‡åµŒå…¥
            print("ðŸ”„ ç”Ÿæˆå‘é‡åµŒå…¥...")
            embeddings = self.embedder.encode(chunks)
            
            # å„²å­˜åˆ°å‘é‡è³‡æ–™åº«
            print("ðŸ’¾ å„²å­˜åˆ°å‘é‡è³‡æ–™åº«...")
            self.vector_store.add_documents(chunks, embeddings, source_name)
            
            # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
            final_stats = self.vector_store.get_stats()
            print(f"âœ… è™•ç†å®Œæˆï¼")
            print(f"ðŸ“Š æœ€çµ‚çµ±è¨ˆ: {final_stats['total_documents']} å€‹æ–‡æª”ç‰‡æ®µ")
            
            return True
        
        except Exception as e:
            print(f"âŒ è™•ç†Notioné é¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def query(self, question: str) -> str:
        """å›žç­”å•é¡Œ"""
        try:
            print(f"ðŸ¤” è™•ç†å•é¡Œ: {question}")
            
            # ç”Ÿæˆå•é¡Œçš„å‘é‡åµŒå…¥
            print("ðŸ”„ ç”Ÿæˆå•é¡ŒåµŒå…¥...")
            question_embedding = self.embedder.encode_single(question)
            
            # æœå°‹ç›¸é—œæ–‡ä»¶
            print("ðŸ” æœå°‹ç›¸é—œå…§å®¹...")
            similar_docs = self.vector_store.search(
                question_embedding, 
                top_k=self.settings.TOP_K
            )
            
            if not similar_docs:
                return "æŠ±æ­‰ï¼Œæˆ‘åœ¨ä½ çš„Notionæ–‡ä»¶ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€‚"
            
            # éŽæ¿¾ä½Žç›¸ä¼¼åº¦çµæžœ
            relevant_docs = [
                doc for doc in similar_docs 
                if doc['score'] >= self.settings.SIMILARITY_THRESHOLD
            ]
            
            if not relevant_docs:
                return f"æŠ±æ­‰ï¼Œæ‰¾åˆ°çš„å…§å®¹ç›¸ä¼¼åº¦å¤ªä½Žï¼ˆæœ€é«˜åˆ†æ•¸: {similar_docs[0]['score']:.3f}ï¼‰ï¼Œç„¡æ³•æä¾›å¯é ç­”æ¡ˆã€‚"
            
            print(f"ðŸ“‹ æ‰¾åˆ° {len(relevant_docs)} å€‹ç›¸é—œæ–‡æª”")
            for i, doc in enumerate(relevant_docs):
                print(f"  {i+1}. ç›¸ä¼¼åº¦: {doc['score']:.3f}")
            
            # çµ„åˆä¸Šä¸‹æ–‡
            context = self._build_context(relevant_docs)
            
            # ç”Ÿæˆå›žç­”
            if self.use_openai:
                answer = self._generate_openai_response(question, context)
            else:
                answer = self._generate_simple_response(question, context)
            
            return answer
            
        except Exception as e:
            print(f"âŒ è™•ç†å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return f"æŠ±æ­‰ï¼Œè™•ç†å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
    
    def _build_context(self, relevant_docs: List[Dict[str, Any]]) -> str:
        """å»ºç«‹ä¸Šä¸‹æ–‡"""
        context_parts = []
        
        for i, doc in enumerate(relevant_docs):
            context_parts.append(f"åƒè€ƒè³‡æ–™ {i+1} (ç›¸ä¼¼åº¦: {doc['score']:.3f}):\n{doc['content']}")
        
        return "\n\n".join(context_parts)
    
    def _generate_openai_response(self, question: str, context: str) -> str:
        """ä½¿ç”¨OpenAIç”Ÿæˆå›žç­”"""
        try:
            prompt = f"""ä½ æ˜¯ä¸€å€‹æœ‰ç”¨çš„åŠ©æ‰‹ï¼Œå°ˆé–€å›žç­”é—œæ–¼Notionæ–‡ä»¶å…§å®¹çš„å•é¡Œã€‚

è«‹åŸºæ–¼ä»¥ä¸‹æä¾›çš„å…§å®¹ä¾†å›žç­”å•é¡Œï¼Œä¸¦éµå¾ªé€™äº›è¦å‰‡ï¼š
1. åªåŸºæ–¼æä¾›çš„åƒè€ƒè³‡æ–™ä¾†å›žç­”
2. å¦‚æžœåƒè€ƒè³‡æ–™ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œè«‹æ˜Žç¢ºèªªæ˜Ž
3. ç”¨ç¹é«”ä¸­æ–‡å›žç­”
4. å›žç­”è¦ç°¡æ½”æ˜Žçž­ï¼Œé‡é»žçªå‡º
5. å¦‚æžœæ˜¯è¡Œç¨‹ç›¸é—œå•é¡Œï¼Œè«‹åŒ…å«å…·é«”çš„æ™‚é–“ã€åœ°é»žç­‰è©³ç´°è³‡è¨Š

åƒè€ƒè³‡æ–™ï¼š
{context}

å•é¡Œï¼š{question}

å›žç­”ï¼š"""

            response = self.openai_client.chat.completions.create(
                model=self.settings.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„åŠ©æ‰‹ï¼Œå°ˆé–€å›žç­”é—œæ–¼æ—…è¡Œè¡Œç¨‹çš„å•é¡Œã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡å›žç­”ï¼Œä¸¦ä¸”åªåŸºæ–¼æä¾›çš„è³‡æ–™ä¾†å›žç­”ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            answer = response.choices[0].message.content.strip()
            print("âœ… OpenAI å›žç­”ç”Ÿæˆå®Œæˆ")
            return answer
            
        except Exception as e:
            print(f"âŒ OpenAI API å‘¼å«å¤±æ•—: {e}")
            # å¦‚æžœOpenAIå¤±æ•—ï¼Œå›žé€€åˆ°ç°¡å–®å›žæ‡‰
            return self._generate_simple_response(question, context)
    
    def _generate_simple_response(self, question: str, context: str) -> str:
        """ç”Ÿæˆç°¡å–®å›žæ‡‰ï¼ˆä¸ä½¿ç”¨OpenAIæ™‚çš„å‚™ç”¨æ–¹æ¡ˆï¼‰"""
        response_parts = [
            f"åŸºæ–¼ä½ çš„Notionå…§å®¹ï¼Œæˆ‘æ‰¾åˆ°ä»¥ä¸‹ç›¸é—œè³‡è¨Šä¾†å›žç­”ã€Œ{question}ã€ï¼š",
            "",
            context,
            "",
            "ä»¥ä¸Šæ˜¯å¾žä½ çš„Notionæ–‡ä»¶ä¸­æ‰¾åˆ°çš„ç›¸é—œå…§å®¹ã€‚"
        ]
        
        return "\n".join(response_parts)
    
    def get_system_status(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±ç‹€æ…‹"""
        stats = self.vector_store.get_stats()
        
        return {
            "vector_database": {
                "total_documents": stats['total_documents'],
                "total_vectors": stats['total_vectors'],
                "sources": stats['source_stats']
            },
            "embedding_model": self.settings.EMBEDDING_MODEL,
            "openai_enabled": self.use_openai,
            "openai_model": self.settings.OPENAI_MODEL if self.use_openai else None,
            "settings": {
                "chunk_size": self.settings.CHUNK_SIZE,
                "chunk_overlap": self.settings.CHUNK_OVERLAP,
                "top_k": self.settings.TOP_K,
                "similarity_threshold": self.settings.SIMILARITY_THRESHOLD
            }
        }
    
    def update_notion_content(self, page_id: str = None) -> bool:
        """æ›´æ–°Notionå…§å®¹"""
        if page_id is None:
            page_id = self.settings.NOTION_PAGE_ID
        
        print("ðŸ”„ æ›´æ–°Notionå…§å®¹...")
        return self.process_notion_page(page_id)