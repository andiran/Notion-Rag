from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List
import torch

class Embedder:
    """å‘é‡åµŒå…¥å™¨"""
    
    def __init__(self, model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"):
        self.model_name = model_name
        print(f"ğŸ”„ è¼‰å…¥åµŒå…¥æ¨¡å‹: {model_name}")
        
        # æª¢æŸ¥è¨­å‚™
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        try:
            self.model = SentenceTransformer(model_name, device=self.device)
            print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            
            # ç²å–æ¨¡å‹è³‡è¨Š
            self.embedding_dimension = self.model.get_sentence_embedding_dimension()
            print(f"ğŸ“ åµŒå…¥ç¶­åº¦: {self.embedding_dimension}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def encode(self, texts: List[str], show_progress: bool = True) -> np.ndarray:
        """å°‡æ–‡æœ¬åˆ—è¡¨ç·¨ç¢¼ç‚ºå‘é‡"""
        if not texts:
            return np.array([])
        
        print(f"ğŸ”„ ç·¨ç¢¼ {len(texts)} å€‹æ–‡æœ¬ç‰‡æ®µ...")
        
        try:
            # éæ¿¾ç©ºæ–‡æœ¬
            valid_texts = [text for text in texts if text.strip()]
            if not valid_texts:
                print("âš ï¸ æ²’æœ‰æœ‰æ•ˆçš„æ–‡æœ¬å¯ä»¥ç·¨ç¢¼")
                return np.array([])
            
            # ç·¨ç¢¼æ–‡æœ¬
            embeddings = self.model.encode(
                valid_texts, 
                convert_to_numpy=True,
                show_progress_bar=show_progress,
                batch_size=32  # è¨­å®šæ‰¹æ¬¡å¤§å°
            )
            
            print(f"âœ… ç·¨ç¢¼å®Œæˆï¼Œå½¢ç‹€: {embeddings.shape}")
            return embeddings
            
        except Exception as e:
            print(f"âŒ ç·¨ç¢¼å¤±æ•—: {e}")
            raise
    
    def encode_single(self, text: str) -> np.ndarray:
        """å°‡å–®å€‹æ–‡æœ¬ç·¨ç¢¼ç‚ºå‘é‡"""
        if not text.strip():
            return np.array([])
        
        try:
            embedding = self.model.encode([text], convert_to_numpy=True)[0]
            return embedding
            
        except Exception as e:
            print(f"âŒ å–®æ–‡æœ¬ç·¨ç¢¼å¤±æ•—: {e}")
            raise
    
    def encode_query(self, query: str) -> np.ndarray:
        """ç·¨ç¢¼æŸ¥è©¢æ–‡æœ¬ï¼ˆèˆ‡encode_singleç›¸åŒï¼Œä½†èªç¾©ä¸Šæ›´æ¸…æ¥šï¼‰"""
        return self.encode_single(query)
    
    def get_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """è¨ˆç®—å…©å€‹å‘é‡çš„é¤˜å¼¦ç›¸ä¼¼åº¦"""
        try:
            # æ­£è¦åŒ–å‘é‡
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(embedding1, embedding2) / (norm1 * norm2)
            return float(similarity)
            
        except Exception as e:
            print(f"âŒ ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
            return 0.0
    
    def test_embedding(self, test_text: str = "é€™æ˜¯ä¸€å€‹æ¸¬è©¦å¥å­") -> bool:
        """æ¸¬è©¦åµŒå…¥åŠŸèƒ½æ˜¯å¦æ­£å¸¸"""
        try:
            print(f"ğŸ§ª æ¸¬è©¦åµŒå…¥åŠŸèƒ½...")
            print(f"æ¸¬è©¦æ–‡æœ¬: {test_text}")
            
            embedding = self.encode_single(test_text)
            
            print(f"âœ… æ¸¬è©¦æˆåŠŸ")
            print(f"åµŒå…¥å½¢ç‹€: {embedding.shape}")
            print(f"åµŒå…¥ç¯„åœ: [{embedding.min():.4f}, {embedding.max():.4f}]")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
            return False