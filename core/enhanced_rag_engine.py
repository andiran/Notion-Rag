from typing import List, Dict, Any, Optional
from datetime import datetime
from .query_processor import QueryProcessor
from .rag_engine import RAGEngine

class EnhancedRAGEngine(RAGEngine):
    """å¢å¼·ç‰ˆ RAG å¼•æ“ - æ”¯æ´å°è©±ä¸Šä¸‹æ–‡"""
    
    def __init__(self, notion_client, text_processor, embedder, vector_store, settings):
        """åˆå§‹åŒ–å¢å¼·ç‰ˆ RAG å¼•æ“"""
        super().__init__(notion_client, text_processor, embedder, vector_store, settings)
        print("ğŸš€ å¢å¼·ç‰ˆ RAG å¼•æ“å·²åˆå§‹åŒ–ï¼Œæ”¯æ´å°è©±ä¸Šä¸‹æ–‡")
    
    def query_with_context(self, question: str, conversation_context: str = "", user_id: str = None) -> str:
        """
        å¸¶ä¸Šä¸‹æ–‡çš„å•ç­”æŸ¥è©¢
        
        Args:
            question: ç”¨æˆ¶å•é¡Œ
            conversation_context: å°è©±ä¸Šä¸‹æ–‡
            user_id: ç”¨æˆ¶IDï¼ˆç”¨æ–¼æ—¥èªŒï¼‰
            
        Returns:
            å›ç­”å­—ä¸²
        """
        try:
            if user_id:
                print(f"ğŸ¤” è™•ç†ç”¨æˆ¶ {user_id} çš„å•é¡Œ: {question}")
            else:
                print(f"ğŸ¤” è™•ç†å•é¡Œ: {question}")
            
            # å¦‚æœæœ‰å°è©±ä¸Šä¸‹æ–‡ï¼Œå…ˆåˆ†ææ˜¯å¦éœ€è¦çµåˆä¸Šä¸‹æ–‡
            context_enhanced_question = self._enhance_question_with_context(question, conversation_context)
            
            # ä½¿ç”¨æŸ¥è©¢è™•ç†å™¨åˆ†æå•é¡Œï¼ˆä½¿ç”¨å¢å¼·å¾Œçš„å•é¡Œï¼‰
            query_analysis = self.query_processor.process_query(context_enhanced_question)
            print(f"ğŸ“Š æŸ¥è©¢åˆ†æçµæœ:")
            print(f"  - æ„åœ–: {query_analysis.intent}")
            print(f"  - é—œéµè©: {query_analysis.keywords}")
            print(f"  - ç½®ä¿¡åº¦: {query_analysis.confidence:.2f}")
            print(f"  - æœå°‹æ¬Šé‡: {query_analysis.search_weights}")
            
            # å¤šéšæ®µæª¢ç´¢
            semantic_docs = []
            keyword_docs = []
            
            # 1. èªç¾©æœå°‹
            semantic_weight = query_analysis.search_weights.get("semantic", query_analysis.search_weights.get("semantic_search", 0))
            keyword_weight = query_analysis.search_weights.get("keyword", query_analysis.search_weights.get("keyword_search", 0))
            
            if semantic_weight > 0:
                print("ğŸ” åŸ·è¡Œèªç¾©æœå°‹...")
                for rewritten_query in query_analysis.rewritten_queries:
                    question_embedding = self.embedder.encode_single(rewritten_query)
                    docs = self.vector_store.search(
                        question_embedding,
                        top_k=self.settings.TOP_K
                    )
                    semantic_docs.extend(docs)
            
            # 2. é—œéµå­—æœå°‹
            if keyword_weight > 0:
                print("ğŸ” åŸ·è¡Œé—œéµå­—æœå°‹...")
                for keyword in query_analysis.keywords:
                    keyword_embedding = self.embedder.encode_single(keyword)
                    docs = self.vector_store.search(
                        keyword_embedding,
                        top_k=self.settings.TOP_K
                    )
                    keyword_docs.extend(docs)
            
            # 3. åˆä½µå’Œå»é‡æ–‡æª”
            all_docs = []
            seen_contents = set()
            
            # è™•ç†èªç¾©æœå°‹çµæœ
            for doc in semantic_docs:
                if doc['content'] not in seen_contents:
                    seen_contents.add(doc['content'])
                    doc['score'] *= semantic_weight
                    all_docs.append(doc)
            
            # è™•ç†é—œéµå­—æœå°‹çµæœ
            for doc in keyword_docs:
                if doc['content'] not in seen_contents:
                    seen_contents.add(doc['content'])
                    doc['score'] *= keyword_weight
                    all_docs.append(doc)
                else:
                    # å¦‚æœæ–‡æª”å·²å­˜åœ¨ï¼Œæ›´æ–°åˆ†æ•¸
                    for existing_doc in all_docs:
                        if existing_doc['content'] == doc['content']:
                            existing_doc['score'] += doc['score'] * keyword_weight
            
            # æŒ‰ç¶œåˆåˆ†æ•¸æ’åº
            all_docs.sort(key=lambda x: x['score'], reverse=True)
            relevant_docs = all_docs[:self.settings.TOP_K]
            
            if not relevant_docs:
                return self._generate_no_result_response(question, conversation_context)
            
            print(f"ğŸ“‹ æ‰¾åˆ° {len(relevant_docs)} å€‹ç›¸é—œæ–‡ä»¶")
            for i, doc in enumerate(relevant_docs):
                print(f"  {i+1}. ç¶œåˆåˆ†æ•¸: {doc['score']:.3f}")
            
            # çµ„åˆä¸Šä¸‹æ–‡
            document_context = self._build_context(relevant_docs)
            
            # ç”Ÿæˆå›ç­”
            if self.use_openai:
                answer = self._generate_context_aware_response(
                    question, document_context, conversation_context, query_analysis
                )
            else:
                answer = self._generate_simple_context_response(
                    question, document_context, conversation_context
                )
            
            return answer
            
        except Exception as e:
            print(f"âŒ è™•ç†å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return f"æŠ±æ­‰ï¼Œè™•ç†å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
    
    def _enhance_question_with_context(self, question: str, conversation_context: str) -> str:
        """
        çµåˆå°è©±ä¸Šä¸‹æ–‡å¢å¼·å•é¡Œ
        
        Args:
            question: åŸå§‹å•é¡Œ
            conversation_context: å°è©±ä¸Šä¸‹æ–‡
            
        Returns:
            å¢å¼·å¾Œçš„å•é¡Œ
        """
        if not conversation_context:
            return question
        
        # æª¢æŸ¥å•é¡Œæ˜¯å¦åŒ…å«ä»£è©æˆ–æŒ‡ç¤ºè©ï¼Œéœ€è¦ä¸Šä¸‹æ–‡ç†è§£
        context_indicators = [
            "é€™å€‹", "é‚£å€‹", "å®ƒ", "ä»–", "å¥¹", "ä¸Šé¢", "å‰›æ‰", "ä¹‹å‰", "æåˆ°çš„",
            "é€™æ¨£", "é‚£æ¨£", "å¦‚ä½•", "æ€éº¼", "ç‚ºä»€éº¼", "é‚„æœ‰", "å¦å¤–", "ç¹¼çºŒ"
        ]
        
        needs_context = any(indicator in question for indicator in context_indicators)
        
        if needs_context:
            # çµåˆä¸Šä¸‹æ–‡å‰µå»ºå¢å¼·å•é¡Œï¼ˆåƒ…ä¾›å…§éƒ¨æŸ¥è©¢ä½¿ç”¨ï¼‰
            enhanced_question = f"{conversation_context}\nç•¶å‰å•é¡Œ: {question}"
            print(f"ğŸ”— å•é¡Œéœ€è¦ä¸Šä¸‹æ–‡ç†è§£ï¼Œå·²å¢å¼·æŸ¥è©¢")
            return enhanced_question
        
        return question
    
    def _generate_context_aware_response(self, question: str, document_context: str, 
                                       conversation_context: str, query_analysis) -> str:
        """
        ç”Ÿæˆè€ƒæ…®å°è©±ä¸Šä¸‹æ–‡çš„ OpenAI å›ç­”
        """
        try:
            # å»ºç«‹ç³»çµ±æç¤º
            system_prompt = """ä½ æ˜¯ä¸€å€‹åŸºæ–¼ Notion æ–‡ä»¶çš„æ™ºæ…§åŠ©æ‰‹ï¼Œå°ˆé–€å›ç­”èˆ‡æ–‡ä»¶å…§å®¹ç›¸é—œçš„å•é¡Œã€‚

è«‹éµå¾ªä»¥ä¸‹è¦å‰‡ï¼š
1. ä¸»è¦åŸºæ–¼æä¾›çš„æ–‡ä»¶å…§å®¹å›ç­”å•é¡Œ
2. è€ƒæ…®å°è©±æ­·ç¨‹ï¼Œä¿æŒå°è©±çš„é€£è²«æ€§
3. å¦‚æœå•é¡Œæ¶‰åŠä¹‹å‰çš„å°è©±å…§å®¹ï¼Œè«‹é©ç•¶å¼•ç”¨
4. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”
5. å›ç­”è¦æº–ç¢ºã€æœ‰å¹«åŠ©ä¸”å‹å–„
6. å¦‚æœæ–‡ä»¶ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œè«‹èª å¯¦èªªæ˜
7. å¯ä»¥é©ç•¶æ¨ç†ï¼Œä½†ä¸è¦ç·¨é€ è³‡è¨Š

å°è©±ä¸Šä¸‹æ–‡å°‡å¹«åŠ©ä½ ç†è§£å•é¡Œçš„èƒŒæ™¯å’Œç”¨æˆ¶çš„æ„åœ–ã€‚"""
            
            # å»ºç«‹ç”¨æˆ¶æç¤º
            user_prompt = f"""åƒè€ƒæ–‡ä»¶å…§å®¹ï¼š
{document_context}

{conversation_context}

è«‹æ ¹æ“šä»¥ä¸Šè³‡è¨Šå›ç­”å•é¡Œï¼š{question}"""
            
            # å‘¼å« OpenAI API
            response = self.openai_client.chat.completions.create(
                model=self.settings.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            answer = response.choices[0].message.content.strip()
            
            # æ·»åŠ ç½®ä¿¡åº¦è³‡è¨Š
            if query_analysis.confidence < 0.5:
                answer += f"\n\nğŸ’¡ æç¤ºï¼šæˆ‘å°é€™å€‹å•é¡Œçš„ç†è§£ç½®ä¿¡åº¦è¼ƒä½ï¼ˆ{query_analysis.confidence:.1%}ï¼‰ï¼Œå¦‚æœå›ç­”ä¸å¤ æº–ç¢ºï¼Œè«‹å˜—è©¦é‡æ–°è¡¨è¿°å•é¡Œã€‚"
            
            return answer
            
        except Exception as e:
            print(f"âŒ OpenAI API å‘¼å«å¤±æ•—: {e}")
            return self._generate_simple_context_response(question, document_context, conversation_context)
    
    def _generate_simple_context_response(self, question: str, document_context: str, 
                                        conversation_context: str) -> str:
        """
        ç”Ÿæˆç°¡å–®çš„ä¸Šä¸‹æ–‡å›ç­”ï¼ˆä¸ä½¿ç”¨ OpenAIï¼‰
        """
        response_parts = []
        
        # å¦‚æœæœ‰å°è©±ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡åƒè€ƒ
        if conversation_context:
            response_parts.append("æ ¹æ“šæˆ‘å€‘ä¹‹å‰çš„å°è©±å’Œæ–‡ä»¶å…§å®¹ï¼š\n")
        else:
            response_parts.append("æ ¹æ“šæ–‡ä»¶å…§å®¹ï¼š\n")
        
        # æ·»åŠ æ–‡ä»¶å…§å®¹æ‘˜è¦
        response_parts.append(document_context)
        
        # æ·»åŠ é‡å°å•é¡Œçš„å»ºè­°
        response_parts.append(f"\né—œæ–¼æ‚¨çš„å•é¡Œã€Œ{question}ã€ï¼Œä»¥ä¸Šå…§å®¹æ‡‰è©²èƒ½æä¾›ç›¸é—œè³‡è¨Šã€‚")
        
        if conversation_context:
            response_parts.append("å¦‚æœæ‚¨éœ€è¦æ›´è©³ç´°çš„è§£é‡‹æˆ–æœ‰å…¶ä»–ç›¸é—œå•é¡Œï¼Œè«‹ç¹¼çºŒè©¢å•ã€‚")
        
        return "\n".join(response_parts)
    
    def _generate_no_result_response(self, question: str, conversation_context: str) -> str:
        """
        ç”Ÿæˆæ‰¾ä¸åˆ°çµæœæ™‚çš„å›ç­”
        """
        base_response = "æŠ±æ­‰ï¼Œæˆ‘åœ¨æ‚¨çš„ Notion æ–‡ä»¶ä¸­æ‰¾ä¸åˆ°ç›´æ¥ç›¸é—œçš„è³‡è¨Šã€‚"
        
        if conversation_context:
            base_response += "é›–ç„¶æˆ‘å€‘ä¹‹å‰æœ‰è¨è«–éä¸€äº›å…§å®¹ï¼Œä½†å°æ–¼é€™å€‹å…·é«”å•é¡Œï¼Œæ–‡ä»¶ä¸­æ²’æœ‰è¶³å¤ çš„è³‡è¨Šã€‚"
        
        suggestions = [
            "æ‚¨å¯ä»¥å˜—è©¦ï¼š",
            "â€¢ é‡æ–°è¡¨è¿°å•é¡Œï¼Œä½¿ç”¨ä¸åŒçš„é—œéµè©",
            "â€¢ æä¾›æ›´å¤šèƒŒæ™¯è³‡è¨Š",
            "â€¢ æª¢æŸ¥ Notion æ–‡ä»¶æ˜¯å¦åŒ…å«ç›¸é—œå…§å®¹",
            "â€¢ è©¢å•æ›´å…·é«”æˆ–æ›´ä¸€èˆ¬çš„å•é¡Œ"
        ]
        
        return base_response + "\n\n" + "\n".join(suggestions)
    
    # ç¹¼æ‰¿çˆ¶é¡çš„å…¶ä»–æ–¹æ³•ï¼Œä¿æŒå‘å¾Œç›¸å®¹æ€§
    def query(self, question: str) -> str:
        """
        å‘å¾Œç›¸å®¹çš„æŸ¥è©¢æ–¹æ³•ï¼ˆç„¡ä¸Šä¸‹æ–‡ï¼‰
        """
        return self.query_with_context(question, "", None) 